{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "#importing the necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation, Flatten, Dropout, Dense\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This model is trained on kaggle soo the directories are of kaggle kernel and not of local machine\n",
    "Batch_size = 32\n",
    "image_size = tuple((256, 256))\n",
    "directory= '../input/plant-village/'\n",
    "width=256\n",
    "height=256\n",
    "depth=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting cv2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ERROR: Could not find a version that satisfies the requirement cv2 (from versions: none)\n",
      "ERROR: No matching distribution found for cv2\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function converts image to array\n",
    "def convert_image_to_array(image_dir):\n",
    "    image = cv2.imread(image_dir)\n",
    "    if image is not None :\n",
    "        image = cv2.resize(image, image_size)   \n",
    "        return img_to_array(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading images ...\n",
      "[INFO] Processing Pepper__bell___Bacterial_spot ...\n",
      "[INFO] Processing Pepper__bell___healthy ...\n",
      "[INFO] Processing Potato___Late_blight ...\n",
      "[INFO] Processing Tomato_Bacterial_spot ...\n",
      "[INFO] Processing Tomato_healthy ...\n",
      "[INFO] Processing Tomato_Leaf_Mold ...\n",
      "[INFO] Processing Tomato_Septoria_leaf_spot ...\n",
      "[INFO] Processing Potato___healthy ...\n",
      "[INFO] Processing Tomato__Target_Spot ...\n",
      "[INFO] Processing Tomato_Spider_mites_Two_spotted_spider_mite ...\n",
      "[INFO] Processing Potato___Early_blight ...\n",
      "[INFO] Processing Tomato_Late_blight ...\n",
      "[INFO] Processing Tomato__Tomato_mosaic_virus ...\n",
      "[INFO] Processing Tomato__Tomato_YellowLeaf__Curl_Virus ...\n",
      "[INFO] Processing Tomato_Early_blight ...\n",
      "[INFO] Image loading completed\n"
     ]
    }
   ],
   "source": [
    "#Reading files nd storing them into image list and label list\n",
    "image_list, label_list = [], []\n",
    "\n",
    "print(\"[INFO] Loading images ...\")\n",
    "root_dir = listdir(directory)\n",
    "    \n",
    "for plant_folder in root_dir :\n",
    "    plant_disease_folder_list = listdir(f\"{directory}/{plant_folder}\")\n",
    "        \n",
    "for plant_disease_folder in plant_disease_folder_list:\n",
    "    print(f\"[INFO] Processing {plant_disease_folder} ...\")\n",
    "    plant_disease_image_list = listdir(f\"{directory}/{plant_folder}/{plant_disease_folder}/\")\n",
    "    for image in plant_disease_image_list[:200]:\n",
    "        image_directory = f\"{directory}/{plant_folder}/{plant_disease_folder}/{image}\"\n",
    "        if image_directory.endswith(\".jpg\") == True or image_directory.endswith(\".JPG\") == True:\n",
    "            image_list.append(convert_image_to_array(image_directory))\n",
    "            label_list.append(plant_disease_folder)\n",
    "print(\"[INFO] Image loading completed\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Labelling our diseases as computer understands numbers and not named diseases\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "lb = LabelBinarizer()\n",
    "image_labels = lb.fit_transform(label_list)\n",
    "pickle.dump(lb,open('label_for_disease.pkl', 'wb'))\n",
    "n_classes = len(lb.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = len(image_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_image_list = np.array(image_list, dtype=np.float16) / 225.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting our data\n",
    "x_train, x_test, y_train, y_test = train_test_split(np_image_list, image_labels, test_size=0.3, random_state = 42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here i am using 300 samples per disease so this samples are used to generate more images with image data generator\n",
    "#The images are flipped and rotated to generate new images\n",
    "aug = ImageDataGenerator(\n",
    "    rotation_range=30, width_shift_range=0.1,\n",
    "    height_shift_range=0.1, shear_range=0.2, \n",
    "    horizontal_flip=True,vertical_flip=True \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating our model\n",
    "model = Sequential()\n",
    "inputShape = (height, width, depth)\n",
    "model.add(Conv2D(32, (3, 3), padding=\"same\",input_shape=inputShape))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(n_classes))\n",
    "model.add(Activation(\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 256, 256, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 256, 256, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 85, 85, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 85, 85, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 85, 85, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 85, 85, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 85, 85, 128)       73856     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 85, 85, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 42, 42, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 42, 42, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 42, 42, 128)       147584    \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 42, 42, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 21, 21, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 21, 21, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 56448)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 15)                846735    \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 15)                0         \n",
      "=================================================================\n",
      "Total params: 1,087,567\n",
      "Trainable params: 1,087,567\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we will use adam optimizer\n",
    "optimizer = Adam(lr=0.001, decay=0.001 /20 )\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=optimizer,metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "64/64 [==============================] - 29s 457ms/step - loss: 0.2380 - accuracy: 0.9336 - val_loss: 0.2357 - val_accuracy: 0.9326\n",
      "Epoch 2/10\n",
      "64/64 [==============================] - 28s 435ms/step - loss: 0.2266 - accuracy: 0.9337 - val_loss: 0.2174 - val_accuracy: 0.9344\n",
      "Epoch 3/10\n",
      "64/64 [==============================] - 28s 432ms/step - loss: 0.2058 - accuracy: 0.9353 - val_loss: 0.2109 - val_accuracy: 0.9301\n",
      "Epoch 4/10\n",
      "64/64 [==============================] - 27s 424ms/step - loss: 0.1929 - accuracy: 0.9359 - val_loss: 0.1740 - val_accuracy: 0.9394\n",
      "Epoch 5/10\n",
      "64/64 [==============================] - 28s 430ms/step - loss: 0.1832 - accuracy: 0.9375 - val_loss: 0.1755 - val_accuracy: 0.9388\n",
      "Epoch 6/10\n",
      "64/64 [==============================] - 27s 424ms/step - loss: 0.1716 - accuracy: 0.9400 - val_loss: 0.1842 - val_accuracy: 0.9361\n",
      "Epoch 7/10\n",
      "64/64 [==============================] - 27s 421ms/step - loss: 0.1646 - accuracy: 0.9413 - val_loss: 0.1610 - val_accuracy: 0.9420\n",
      "Epoch 8/10\n",
      "64/64 [==============================] - 27s 428ms/step - loss: 0.1531 - accuracy: 0.9437 - val_loss: 0.1625 - val_accuracy: 0.9431\n",
      "Epoch 9/10\n",
      "64/64 [==============================] - 29s 452ms/step - loss: 0.1496 - accuracy: 0.9455 - val_loss: 0.1697 - val_accuracy: 0.9418\n",
      "Epoch 10/10\n",
      "64/64 [==============================] - 29s 456ms/step - loss: 0.1461 - accuracy: 0.9464 - val_loss: 0.1899 - val_accuracy: 0.9351\n"
     ]
    }
   ],
   "source": [
    "#Training the model for 10 epochs\n",
    "history = model.fit_generator(\n",
    "    aug.flow(x_train, y_train, batch_size=Batch_size),\n",
    "    validation_data=(x_test, y_test),\n",
    "    steps_per_epoch=len(x_train) // Batch_size,\n",
    "    epochs=10, verbose=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "885/885 [==============================] - 2s 2ms/step\n",
      "Test Accuracy: 93.51412653923035\n"
     ]
    }
   ],
   "source": [
    "#Here the accuracy of model is 93.51 which is quite good\n",
    "scores = model.evaluate(x_test, y_test)\n",
    "print(f\"Test Accuracy: {scores[1]*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the trained model for further use\n",
    "pickle.dump(model,open('cnn_model_plant_disease.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading our prtrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " 'cnn_model_plant_disease.pkl',\n",
       " 'Plant disease classification 1512.ipynb']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from os import listdir\n",
    "listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1216 14:26:02.485614  4368 deprecation_wrapper.py:119] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W1216 14:26:05.273987  4368 deprecation.py:323] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W1216 14:26:08.199764  4368 deprecation_wrapper.py:119] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model=pickle.load(open('cnn_model_plant_disease.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 256, 256, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 256, 256, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 85, 85, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 85, 85, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 85, 85, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 85, 85, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 85, 85, 128)       73856     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 85, 85, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 42, 42, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 42, 42, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 42, 42, 128)       147584    \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 42, 42, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 21, 21, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 21, 21, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 56448)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 15)                846735    \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 15)                0         \n",
      "=================================================================\n",
      "Total params: 1,087,567\n",
      "Trainable params: 1,087,567\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
